<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audiovisual Art Studio</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #0a0e27;
            color: #e0e0e0;
            overflow: hidden;
        }
        #canvas {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        #ui {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            display: flex;
            align-items: center;
            justify-content: center;
            pointer-events: none;
        }
        #upload-area {
            background: rgba(255, 255, 255, 0.05);
            backdrop-filter: blur(10px);
            border: 2px dashed rgba(102, 126, 234, 0.4);
            border-radius: 20px;
            padding: 3rem 4rem;
            text-align: center;
            pointer-events: all;
            cursor: pointer;
            transition: all 0.3s;
        }
        #upload-area:hover { border-color: #667eea; background: rgba(102, 126, 234, 0.1); }
        #upload-area.hidden { display: none; }
        h1 { font-size: 2rem; margin-bottom: 1rem; 
             background: linear-gradient(135deg, #667eea, #764ba2);
             -webkit-background-clip: text; -webkit-text-fill-color: transparent; }
        #controls {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(0, 0, 0, 0.8);
            backdrop-filter: blur(10px);
            padding: 1rem 2rem;
            border-radius: 50px;
            display: none;
            gap: 1rem;
            align-items: center;
        }
        #controls.show { display: flex; }
        button {
            background: #667eea;
            border: none;
            color: white;
            padding: 0.75rem 1.5rem;
            border-radius: 25px;
            cursor: pointer;
            font-size: 1rem;
            transition: all 0.2s;
        }
        button:hover { background: #764ba2; transform: scale(1.05); }
        .info { font-size: 0.9rem; opacity: 0.8; }
    </style>
</head>
<body>
    <canvas id="canvas"></canvas>
    <div id="ui">
        <div id="upload-area">
            <h1>üéµ Audiovisual Art Studio</h1>
            <p>Drop an audio file here or click to browse</p>
            <p class="info" style="margin-top: 1rem;">Supports MP3, WAV, OGG, FLAC</p>
            <input type="file" id="fileInput" accept="audio/*" style="display: none;">
        </div>
    </div>
    <div id="controls">
        <button id="playBtn">‚ñ∂Ô∏è Play</button>
        <button id="stopBtn">‚èπÔ∏è Stop</button>
        <span id="status" class="info"></span>
    </div>

    <script>
        const canvas = document.getElementById('canvas');
        const gl = canvas.getContext('webgl2');
        const uploadArea = document.getElementById('upload-area');
        const fileInput = document.getElementById('fileInput');
        const controls = document.getElementById('controls');
        const playBtn = document.getElementById('playBtn');
        const stopBtn = document.getElementById('stopBtn');
        const status = document.getElementById('status');

        let audioContext, analyser, source, audioBuffer;
        let animationId;
        let isPlaying = false;

        // Resize canvas
        function resize() {
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
            gl.viewport(0, 0, canvas.width, canvas.height);
        }
        window.addEventListener('resize', resize);
        resize();

        // Shader setup
        const vertexShader = gl.createShader(gl.VERTEX_SHADER);
        gl.shaderSource(vertexShader, `
            attribute vec2 position;
            void main() {
                gl_Position = vec4(position, 0.0, 1.0);
            }
        `);
        gl.compileShader(vertexShader);

        const fragmentShader = gl.createShader(gl.FRAGMENT_SHADER);
        gl.shaderSource(fragmentShader, `
            precision mediump float;
            uniform vec2 resolution;
            uniform float time;
            uniform float bass;
            uniform float mid;
            uniform float treble;
            
            void main() {
                vec2 uv = gl_FragCoord.xy / resolution.xy;
                vec2 center = vec2(0.5);
                float dist = length(uv - center);
                
                // Audio-reactive colors
                float r = sin(time + bass * 3.0) * 0.5 + 0.5;
                float g = sin(time * 1.5 + mid * 2.0) * 0.5 + 0.5;
                float b = sin(time * 2.0 + treble) * 0.5 + 0.5;
                
                // Circular waves
                float wave = sin(dist * 20.0 - time * 2.0 + bass * 10.0) * 0.5 + 0.5;
                
                // Radial gradient with audio reactivity
                float vignette = 1.0 - dist * (1.5 - bass * 0.5);
                
                vec3 color = vec3(r, g, b) * wave * vignette;
                gl_FragColor = vec4(color, 1.0);
            }
        `);
        gl.compileShader(fragmentShader);

        const program = gl.createProgram();
        gl.attachShader(program, vertexShader);
        gl.attachShader(program, fragmentShader);
        gl.linkProgram(program);
        gl.useProgram(program);

        // Setup quad
        const positions = new Float32Array([-1, -1, 1, -1, -1, 1, 1, 1]);
        const buffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
        gl.bufferData(gl.ARRAY_BUFFER, positions, gl.STATIC_DRAW);
        
        const positionLocation = gl.getAttribLocation(program, 'position');
        gl.enableVertexAttribArray(positionLocation);
        gl.vertexAttribPointer(positionLocation, 2, gl.FLOAT, false, 0, 0);

        const resolutionLocation = gl.getUniformLocation(program, 'resolution');
        const timeLocation = gl.getUniformLocation(program, 'time');
        const bassLocation = gl.getUniformLocation(program, 'bass');
        const midLocation = gl.getUniformLocation(program, 'mid');
        const trebleLocation = gl.getUniformLocation(program, 'treble');

        // Audio analysis
        function setupAudio(arrayBuffer) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 512;
            
            audioContext.decodeAudioData(arrayBuffer, (buffer) => {
                audioBuffer = buffer;
                uploadArea.classList.add('hidden');
                controls.classList.add('show');
                status.textContent = `Ready ‚Ä¢ ${buffer.duration.toFixed(1)}s`;
            });
        }

        function play() {
            if (!audioBuffer || isPlaying) return;
            
            source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(analyser);
            analyser.connect(audioContext.destination);
            source.start();
            isPlaying = true;
            playBtn.textContent = '‚è∏Ô∏è Pause';
            
            source.onended = () => {
                isPlaying = false;
                playBtn.textContent = '‚ñ∂Ô∏è Play';
            };
        }

        function stop() {
            if (source) {
                source.stop();
                source.disconnect();
                isPlaying = false;
                playBtn.textContent = '‚ñ∂Ô∏è Play';
            }
        }

        // Render loop
        function render() {
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            analyser.getByteFrequencyData(dataArray);
            
            // Extract frequency bands
            const bass = dataArray.slice(0, 10).reduce((a, b) => a + b, 0) / 10 / 255;
            const mid = dataArray.slice(10, 30).reduce((a, b) => a + b, 0) / 20 / 255;
            const treble = dataArray.slice(30, 60).reduce((a, b) => a + b, 0) / 30 / 255;
            
            gl.uniform2f(resolutionLocation, canvas.width, canvas.height);
            gl.uniform1f(timeLocation, performance.now() / 1000);
            gl.uniform1f(bassLocation, bass);
            gl.uniform1f(midLocation, mid);
            gl.uniform1f(trebleLocation, treble);
            
            gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
            animationId = requestAnimationFrame(render);
        }
        render();

        // File handling
        uploadArea.addEventListener('click', () => fileInput.click());
        fileInput.addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (file) {
                const reader = new FileReader();
                reader.onload = (e) => setupAudio(e.target.result);
                reader.readAsArrayBuffer(file);
            }
        });

        uploadArea.addEventListener('dragover', (e) => {
            e.preventDefault();
            uploadArea.style.borderColor = '#667eea';
        });
        uploadArea.addEventListener('drop', (e) => {
            e.preventDefault();
            const file = e.dataTransfer.files[0];
            if (file) {
                const reader = new FileReader();
                reader.onload = (e) => setupAudio(e.target.result);
                reader.readAsArrayBuffer(file);
            }
        });

        playBtn.addEventListener('click', play);
        stopBtn.addEventListener('click', stop);
    </script>
</body>
</html>
